{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef031375-6aff-4b99-9b07-37c576f92e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install highway-env\n",
    "# !pip install git+https://github.com/DLR-RM/stable-baselines3\n",
    "# !pip install tensorboardx gym pyvirtualdisplay\n",
    "# !apt-get install -y xvfb python-opengl ffmpeg\n",
    "# !git clone https://github.com/eleurent/highway-env.git 2> /dev/null\n",
    "# !git clone https://github.com/avivg7/highway-config.git\n",
    "# !pip install tensorboard\n",
    "# !pip install xvfbwrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c2a559-404e-4a2d-b709-a65972057e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/cffi/cparser.py:165: UserWarning: Global variable 'stderr' in cdef(): for consistency with C it should have a storage class specifier (usually 'extern')\n",
      "  \"(usually 'extern')\" % (decl.name,))\n",
      "/opt/conda/lib/python3.7/site-packages/cffi/cparser.py:165: UserWarning: Global variable '__stderrp' in cdef(): for consistency with C it should have a storage class specifier (usually 'extern')\n",
      "  \"(usually 'extern')\" % (decl.name,))\n"
     ]
    }
   ],
   "source": [
    "from cffi import FFI\n",
    "import os\n",
    "\n",
    "ffi = FFI()\n",
    "ffi.cdef(\"\"\"\n",
    "/* from stdio.h */\n",
    "FILE* fopen(const char* path, const char* mode);\n",
    "int fclose(FILE* fp);\n",
    "FILE* stderr;  /* GNU C library */\n",
    "FILE* __stderrp;  /* Mac OS X */\n",
    "\"\"\")\n",
    "try:\n",
    "    stdio = ffi.dlopen(None)\n",
    "    devnull = stdio.fopen(os.devnull.encode(), b'w')\n",
    "except OSError:\n",
    "    pass\n",
    "try:\n",
    "    stdio.stderr = devnull\n",
    "except KeyError:\n",
    "    try:\n",
    "        stdio.__stderrp = devnull\n",
    "    except KeyError:\n",
    "        stdio.fclose(devnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6779162-b029-4026-b66d-cb325698adea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.7.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import sys\n",
    "sys.path.insert(0, '/content/highway-env/scripts/')\n",
    "import io\n",
    "import base64\n",
    "import os\n",
    "from tqdm.notebook import trange\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pygame\n",
    "import json\n",
    "import ast\n",
    "from pprint import pprint \n",
    "import glob\n",
    "from collections import Counter\n",
    "\n",
    "# Local\n",
    "from final_project.display_utils import wrap_env, show_video\n",
    "from models.agent import Agent\n",
    "from models.utils import plot_learning_curve\n",
    "\n",
    "# Gym Env\n",
    "import gym\n",
    "import highway_env\n",
    "# from utils import record_videos, show_videos\n",
    "from gym import logger as gymlogger\n",
    "from gym.wrappers import Monitor\n",
    "from gym.utils import seeding\n",
    "from gym import error, spaces, utils\n",
    "gymlogger.set_level(40) # error only\n",
    "\n",
    "# Neural Networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from pyvirtualdisplay import Display\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e7aeeb5-bfd6-4abe-9ba1-10781109dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff54115e-c798-4170-883e-01bc0a09e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #=============== DO NOT DELETE ===============\n",
    "# file = open('./highway-config/config_ex1.txt', 'r')\n",
    "# contents = file.read()\n",
    "# config1 = ast.literal_eval(contents)\n",
    "# file.close()\n",
    "# # ============================================\n",
    "\n",
    "# env = gym.make(\"highway-fast-v0\")\n",
    "# env.configure(config1)\n",
    "\n",
    "# obs = env.reset()\n",
    "# for j in range(10):\n",
    "#     obs, _, _, _ = env.step(0)\n",
    "\n",
    "#     _, axes = plt.subplots(ncols=4, figsize=(12, 5))\n",
    "#     for i, ax in enumerate(axes.flat):\n",
    "#         ax.imshow(obs[i, ...].T, cmap=plt.get_cmap('gray'))\n",
    "    \n",
    "\n",
    "# env = wrap_env(env)\n",
    "# env.reset()\n",
    "# done = False\n",
    "# iter = 0\n",
    "\n",
    "# while (iter < 10) or not done:\n",
    "#   if done:\n",
    "#     break\n",
    "#   iter +=1\n",
    "#   action = env.action_space.sample()\n",
    "#   observation, reward, done, _ = env.step(action)\n",
    "#   screen = env.render(mode='rgb_array')\n",
    "#   plt.imshow(screen)\n",
    "#   print(f'iteration: {iter}, action: {action}, reward: {reward}, done: {done}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a794abc-5326-49a0-b30f-f3cd6e9d40d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c18e2d7-f457-4c3a-b84e-fb851f1cf429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[99., 99., 99., ..., 99., 99., 99.],\n",
       "        [99., 99., 99., ..., 99., 99., 99.],\n",
       "        [99., 99., 99., ..., 99., 99., 99.],\n",
       "        ...,\n",
       "        [99., 99., 99., ..., 99., 99., 99.],\n",
       "        [99., 99., 99., ..., 99., 99., 99.],\n",
       "        [99., 99., 99., ..., 99., 99., 99.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=============== DO NOT DELETE ===============\n",
    "# file = open('/content/highway-config/config_ex1.txt', 'r')\n",
    "# contents = file.read()\n",
    "# config1 = ast.literal_eval(contents)\n",
    "# file.close()\n",
    "# ============================================\n",
    "\n",
    "file = open('./highway-config/config_ex1.txt', 'r')\n",
    "contents = file.read()\n",
    "# print(contents)\n",
    "config1 = ast.literal_eval(contents)\n",
    "file.close()\n",
    "\n",
    "env = gym.make(\"highway-fast-v0\")\n",
    "env.configure(config1)\n",
    "# env = wrap_env(env)\n",
    "env.reset()\n",
    "# env.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5e244b-e18b-4ec3-967d-26f2b25508dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.max(observation)\n",
    "\n",
    "# while a == 0:\n",
    "#     action = env.action_space.sample()\n",
    "#     observation, reward, done, _ = env.step(action)\n",
    "#     a = np.max(observation)\n",
    "# print(f'np.max(observation): {np.max(observation)}')\n",
    "# print(f'np.min(observation): {np.min(observation)}')    \n",
    "# for i in range(100):\n",
    "#     action = env.action_space.sample()\n",
    "#     observation, reward, done, _ = env.step(action)\n",
    "\n",
    "#     pprint(action)\n",
    "# # pprint(observation)\n",
    "#     print(f'np.max(observation): {np.max(observation)}')\n",
    "#     print(f'np.min(observation): {np.min(observation)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c06e2ed1-c479-47ad-bbee-a1a4d1f2aa8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 128, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d919a47-82ed-45a0-a69c-6af8f90ef0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97a80b27-236d-4ded-aa73-d4b13ae15f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4, 128, 128)\n",
      "4 128 128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/highway-rl/models/agent.py:58: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755953518/work/torch/csrc/utils/tensor_new.cpp:210.)\n",
      "  state = T.Tensor([observation]).to(self.actor.device)\n",
      "/home/jupyter/highway-rl/models/networks.py:137: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  prob = F.softmax(prob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Best Score 19.050878684176222, Average Score: 19.050878684176222, Top Score: 19.050878684176222\n",
      "action_history: (array([0.        , 0.31818182, 0.27272727, 0.40909091]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 1, Best Score 19.050878684176222, Average Score: 13.622748508541681, Top Score: 19.050878684176222\n",
      "action_history: (array([0.03125, 0.34375, 0.3125 , 0.3125 ]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 2, Best Score 19.050878684176222, Average Score: 14.417367270355035, Top Score: 19.050878684176222\n",
      "action_history: (array([0.06, 0.4 , 0.28, 0.26]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 3, Best Score 33.193585747787495, Average Score: 33.193585747787495, Top Score: 89.52224118008486\n",
      "action_history: (array([0.12048193, 0.31325301, 0.21084337, 0.35542169]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 4, Best Score 33.193585747787495, Average Score: 28.773488750646912, Top Score: 89.52224118008486\n",
      "action_history: (array([0.12290503, 0.30726257, 0.2122905 , 0.3575419 ]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 5, Best Score 33.193585747787495, Average Score: 27.794611062229276, Top Score: 89.52224118008486\n",
      "action_history: (array([0.13333333, 0.29047619, 0.21904762, 0.35714286]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 6, Best Score 33.193585747787495, Average Score: 26.385428406279907, Top Score: 89.52224118008486\n",
      "action_history: (array([0.12121212, 0.2987013 , 0.23376623, 0.34632035]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 7, Best Score 35.70936921083839, Average Score: 35.70936921083839, Top Score: 100.97695484274777\n",
      "action_history: (array([0.08042895, 0.19839142, 0.16353887, 0.55764075]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 8, Best Score 71.33323045529404, Average Score: 71.33323045529404, Top Score: 356.3241204109392\n",
      "action_history: (array([0.03436426, 0.08476518, 0.069874  , 0.81099656]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 9, Best Score 99.5754260598053, Average Score: 99.5754260598053, Top Score: 356.3241204109392\n",
      "action_history: (array([0.02184996, 0.05389658, 0.04442826, 0.8798252 ]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 10, Best Score 123.68381350655814, Average Score: 123.68381350655814, Top Score: 364.76768797408647\n",
      "action_history: (array([0.01601708, 0.03950881, 0.03256807, 0.91190603]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 11, Best Score 123.68381350655814, Average Score: 121.74498465182853, Top Score: 364.76768797408647\n",
      "action_history: (array([0.01485149, 0.03663366, 0.03019802, 0.91831683]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 12, Best Score 139.30317225502503, Average Score: 139.30317225502503, Top Score: 364.76768797408647\n",
      "action_history: (array([0.01190476, 0.02936508, 0.02420635, 0.93452381]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 13, Best Score 153.96434608164424, Average Score: 153.96434608164424, Top Score: 364.76768797408647\n",
      "action_history: (array([0.00993377, 0.02450331, 0.02019868, 0.94536424]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 14, Best Score 167.08896886479505, Average Score: 167.08896886479505, Top Score: 364.76768797408647\n",
      "action_history: (array([0.00852273, 0.02102273, 0.01732955, 0.953125  ]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 15, Best Score 167.08896886479505, Average Score: 160.6544776125653, Top Score: 364.76768797408647\n",
      "action_history: (array([0.00830105, 0.02047593, 0.0168788 , 0.95434422]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 16, Best Score 167.08896886479505, Average Score: 155.06724461192448, Top Score: 364.76768797408647\n",
      "action_history: (array([0.00809061, 0.01995685, 0.01645092, 0.95550162]), array([0, 1, 2, 3, 4]))\n",
      "\n",
      "Episode: 17, Best Score 167.08896886479505, Average Score: 149.70546894694675, Top Score: 364.76768797408647\n",
      "action_history: (array([0.00791975, 0.01953537, 0.01610348, 0.95644139]), array([0, 1, 2, 3, 4]))\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26348/452084944.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_observation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mload_checkpoint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_observation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mscore_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/highway-rl/models/agent.py\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mactor_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m         \u001b[0mactor_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_games = 500\n",
    "figure_file = 'plots/highway_500'\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "# print(env.observation_space.shape)\n",
    "agent = Agent(input_dims=env.observation_space.shape,\n",
    "              env=env,\n",
    "              n_actions=5,\n",
    "              max_size=10000)\n",
    "\n",
    "best_score = env.reward_range[0]\n",
    "top_score = env.reward_range[0]\n",
    "score_history = []\n",
    "load_checkpoint = False\n",
    "action_history = []\n",
    "\n",
    "if load_checkpoint:\n",
    "    agent.load_models()\n",
    "    env.render(mode='human')\n",
    "    \n",
    "for i in range(n_games):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        action = agent.choose_action(observation)\n",
    "        action_history.append(action)\n",
    "        salt = np.random.rand()\n",
    "        if salt > 0.15:\n",
    "            new_observation, reward, done, info = env.step(action)\n",
    "            if action == 4 and salt < 0.7:\n",
    "                reward = 0.8*reward\n",
    "        else:\n",
    "            new_observation, reward, done, info = env.step(env.action_space.sample())\n",
    "        score += reward\n",
    "        # print(f'observation.shape: {observation.shape}')\n",
    "        agent.remember(observation, action, reward, new_observation, done)\n",
    "        if not load_checkpoint:\n",
    "            agent.learn()\n",
    "        observation = new_observation\n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-100:])\n",
    "    \n",
    "    top_score = max(score, top_score)\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        if not load_checkpoint:\n",
    "            agent.save_models()\n",
    "    \n",
    "    screen = env.render(mode='rgb_array')\n",
    "    plt.imshow(screen)\n",
    "    print(f'Episode: {i}, Best Score {best_score}, Average Score: {avg_score}, Top Score: {top_score}')\n",
    "    print(f'action_history: {np.histogram(action_history, bins=np.arange(5), density=True)}\\n')\n",
    "    \n",
    "if not load_checkpoint:\n",
    "    x = [i+1 for i in range(n_games)]\n",
    "    plot_learning_curve(x, score_history, figure_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743b86c-61ec-42ef-953d-bb0744002314",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load_checkpoint:\n",
    "    x = [i+1 for i in range(n_games)]\n",
    "    plot_learning_curve(x, score_history, figure_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f08b8ba-9594-4501-ae2f-d5d6b4cbdb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()\n",
    "# show_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7dd900-f1ec-4329-84bd-8ece5dc41419",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.uniform(m.weight,  -3*1.e-4, 3*1.e-4)\n",
    "            m.bias.data.fill_(0.0001)\n",
    "\n",
    "class ActorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActorNet, self).__init__()\n",
    "        self.shared_layers = nn.Sequential( # todo: name\n",
    "            nn.Conv2d(4, 32, kernel_size=8, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(start_dim=0),\n",
    "            nn.Linear(64*12*12, 5),\n",
    "        )\n",
    "        self.shared_layers.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = torch.tensor(x, dtype=torch.float)\n",
    "        hidden = self.shared_layers(input_tensor)\n",
    "        #output = self.output(hidden)\n",
    "        actions_probs = Categorical(F.softmax(hidden, dim=-1))\n",
    "\n",
    "        return actions_probs, hidden\n",
    "\n",
    "class CriticNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CriticNet, self).__init__()\n",
    "        self.shared_layers = nn.Sequential(  # todo: name\n",
    "            nn.Conv2d(4, 32, kernel_size=8, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(start_dim=0),\n",
    "            nn.Linear(64 * 12 * 12, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = torch.FloatTensor(x)\n",
    "        hidden = self.shared_layers(input_tensor)\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5914c78-bcd4-498e-be74-5bb539a436ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
