{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef031375-6aff-4b99-9b07-37c576f92e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install highway-env\n",
    "# !pip install git+https://github.com/DLR-RM/stable-baselines3\n",
    "# !pip install tensorboardx gym pyvirtualdisplay\n",
    "# !apt-get install -y xvfb python-opengl ffmpeg\n",
    "# !git clone https://github.com/eleurent/highway-env.git 2> /dev/null\n",
    "# !git clone https://github.com/avivg7/highway-config.git\n",
    "# !pip install tensorboard\n",
    "# !pip install xvfbwrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72c2a559-404e-4a2d-b709-a65972057e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/cffi/cparser.py:165: UserWarning: Global variable 'stderr' in cdef(): for consistency with C it should have a storage class specifier (usually 'extern')\n",
      "  \"(usually 'extern')\" % (decl.name,))\n",
      "/opt/conda/lib/python3.7/site-packages/cffi/cparser.py:165: UserWarning: Global variable '__stderrp' in cdef(): for consistency with C it should have a storage class specifier (usually 'extern')\n",
      "  \"(usually 'extern')\" % (decl.name,))\n"
     ]
    }
   ],
   "source": [
    "from cffi import FFI\n",
    "import os\n",
    "\n",
    "ffi = FFI()\n",
    "ffi.cdef(\"\"\"\n",
    "/* from stdio.h */\n",
    "FILE* fopen(const char* path, const char* mode);\n",
    "int fclose(FILE* fp);\n",
    "FILE* stderr;  /* GNU C library */\n",
    "FILE* __stderrp;  /* Mac OS X */\n",
    "\"\"\")\n",
    "try:\n",
    "    stdio = ffi.dlopen(None)\n",
    "    devnull = stdio.fopen(os.devnull.encode(), b'w')\n",
    "except OSError:\n",
    "    pass\n",
    "try:\n",
    "    stdio.stderr = devnull\n",
    "except KeyError:\n",
    "    try:\n",
    "        stdio.__stderrp = devnull\n",
    "    except KeyError:\n",
    "        stdio.fclose(devnull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d6779162-b029-4026-b66d-cb325698adea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.16, Python 3.7.12)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# General\n",
    "import sys\n",
    "sys.path.insert(0, '/content/highway-env/scripts/')\n",
    "import io\n",
    "import base64\n",
    "import os\n",
    "from tqdm.notebook import trange\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import pygame\n",
    "import json\n",
    "import ast\n",
    "from pprint import pprint \n",
    "import glob\n",
    "from collections import Counter\n",
    "\n",
    "# Local\n",
    "from final_project.display_utils import wrap_env, show_video\n",
    "from models.agent import Agent\n",
    "from models.utils import plot_learning_curve\n",
    "\n",
    "# Gym Env\n",
    "import gym\n",
    "import highway_env\n",
    "# from utils import record_videos, show_videos\n",
    "from gym import logger as gymlogger\n",
    "from gym.wrappers import Monitor\n",
    "from gym.utils import seeding\n",
    "from gym import error, spaces, utils\n",
    "gymlogger.set_level(40) # error only\n",
    "\n",
    "# Neural Networks\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from pyvirtualdisplay import Display\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "%load_ext tensorboard\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e7aeeb5-bfd6-4abe-9ba1-10781109dbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff54115e-c798-4170-883e-01bc0a09e452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #=============== DO NOT DELETE ===============\n",
    "# file = open('./highway-config/config_ex1.txt', 'r')\n",
    "# contents = file.read()\n",
    "# config1 = ast.literal_eval(contents)\n",
    "# file.close()\n",
    "# # ============================================\n",
    "\n",
    "# env = gym.make(\"highway-fast-v0\")\n",
    "# env.configure(config1)\n",
    "\n",
    "# obs = env.reset()\n",
    "# for j in range(10):\n",
    "#     obs, _, _, _ = env.step(0)\n",
    "\n",
    "#     _, axes = plt.subplots(ncols=4, figsize=(12, 5))\n",
    "#     for i, ax in enumerate(axes.flat):\n",
    "#         ax.imshow(obs[i, ...].T, cmap=plt.get_cmap('gray'))\n",
    "    \n",
    "\n",
    "# env = wrap_env(env)\n",
    "# env.reset()\n",
    "# done = False\n",
    "# iter = 0\n",
    "\n",
    "# while (iter < 10) or not done:\n",
    "#   if done:\n",
    "#     break\n",
    "#   iter +=1\n",
    "#   action = env.action_space.sample()\n",
    "#   observation, reward, done, _ = env.step(action)\n",
    "#   screen = env.render(mode='rgb_array')\n",
    "#   plt.imshow(screen)\n",
    "#   print(f'iteration: {iter}, action: {action}, reward: {reward}, done: {done}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a794abc-5326-49a0-b30f-f3cd6e9d40d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c18e2d7-f457-4c3a-b84e-fb851f1cf429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       "\n",
       "       [[99., 99., 99., ..., 99., 99., 99.],\n",
       "        [99., 99., 99., ..., 99., 99., 99.],\n",
       "        [99., 99., 99., ..., 99., 99., 99.],\n",
       "        ...,\n",
       "        [99., 99., 99., ..., 99., 99., 99.],\n",
       "        [99., 99., 99., ..., 99., 99., 99.],\n",
       "        [99., 99., 99., ..., 99., 99., 99.]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#=============== DO NOT DELETE ===============\n",
    "# file = open('/content/highway-config/config_ex1.txt', 'r')\n",
    "# contents = file.read()\n",
    "# config1 = ast.literal_eval(contents)\n",
    "# file.close()\n",
    "# ============================================\n",
    "\n",
    "file = open('./highway-config/config_ex1.txt', 'r')\n",
    "contents = file.read()\n",
    "# print(contents)\n",
    "config1 = ast.literal_eval(contents)\n",
    "file.close()\n",
    "\n",
    "env = gym.make(\"highway-fast-v0\")\n",
    "env.configure(config1)\n",
    "# env = wrap_env(env)\n",
    "env.reset()\n",
    "# env.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb5e244b-e18b-4ec3-967d-26f2b25508dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = np.max(observation)\n",
    "\n",
    "# while a == 0:\n",
    "#     action = env.action_space.sample()\n",
    "#     observation, reward, done, _ = env.step(action)\n",
    "#     a = np.max(observation)\n",
    "# print(f'np.max(observation): {np.max(observation)}')\n",
    "# print(f'np.min(observation): {np.min(observation)}')    \n",
    "# for i in range(100):\n",
    "#     action = env.action_space.sample()\n",
    "#     observation, reward, done, _ = env.step(action)\n",
    "\n",
    "#     pprint(action)\n",
    "# # pprint(observation)\n",
    "#     print(f'np.max(observation): {np.max(observation)}')\n",
    "#     print(f'np.min(observation): {np.min(observation)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c06e2ed1-c479-47ad-bbee-a1a4d1f2aa8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 128, 128)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d919a47-82ed-45a0-a69c-6af8f90ef0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# del agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97a80b27-236d-4ded-aa73-d4b13ae15f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4, 128, 128)\n",
      "4 128 128\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25818/3911242173.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mavg_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore_history\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mtop_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mavg_score\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbest_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mbest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mamax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mamax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2704\u001b[0m     \"\"\"\n\u001b[1;32m   2705\u001b[0m     return _wrapreduction(a, np.maximum, 'max', axis, None, out,\n\u001b[0;32m-> 2706\u001b[0;31m                           keepdims=keepdims, initial=initial, where=where)\n\u001b[0m\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_amax\u001b[0;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     37\u001b[0m def _amax(a, axis=None, out=None, keepdims=False,\n\u001b[1;32m     38\u001b[0m           initial=_NoValue, where=True):\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_maximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m def _amin(a, axis=None, out=None, keepdims=False,\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "n_games = 500\n",
    "figure_file = 'plots/highway_500'\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "# print(env.observation_space.shape)\n",
    "agent = Agent(input_dims=env.observation_space.shape,\n",
    "              env=env,\n",
    "              n_actions=5,\n",
    "              max_size=10000)\n",
    "\n",
    "best_score = env.reward_range[0]\n",
    "top_score = env.reward_range[0]\n",
    "score_history = []\n",
    "load_checkpoint = False\n",
    "action_history = []\n",
    "\n",
    "if load_checkpoint:\n",
    "    agent.load_models()\n",
    "    env.render(mode='human')\n",
    "    \n",
    "for i in range(n_games):\n",
    "    observation = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    while not done:\n",
    "        action = agent.choose_action(observation)\n",
    "        action_history.append(action)\n",
    "        if np.random.rand() > 0.15:\n",
    "            new_observation, reward, done, info = env.step(action)\n",
    "        else:\n",
    "            new_observation, reward, done, info = env.step(env.action_space.sample())\n",
    "        score += reward\n",
    "        # print(f'observation.shape: {observation.shape}')\n",
    "        agent.remember(observation, action, reward, new_observation, done)\n",
    "        if not load_checkpoint:\n",
    "            agent.learn()\n",
    "        observation = new_observation\n",
    "    score_history.append(score)\n",
    "    avg_score = np.mean(score_history[-100:])\n",
    "    \n",
    "    top_score = max(score, top_score)\n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        if not load_checkpoint:\n",
    "            agent.save_models()\n",
    "    \n",
    "    screen = env.render(mode='rgb_array')\n",
    "    plt.imshow(screen)\n",
    "    print(f'Episode: {i}, Best Score {best_score}, Average Score: {avg_score}, Top Score: {top_score}')\n",
    "    print(f'action_history: {np.histogram(action_history, bins=np.arange(5), density=True)}\\n')\n",
    "    \n",
    "if not load_checkpoint:\n",
    "    x = [i+1 for i in range(n_games)]\n",
    "    plot_learning_curve(x, score_history, figure_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7743b86c-61ec-42ef-953d-bb0744002314",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not load_checkpoint:\n",
    "    x = [i+1 for i in range(n_games)]\n",
    "    plot_learning_curve(x, score_history, figure_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f08b8ba-9594-4501-ae2f-d5d6b4cbdb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()\n",
    "# show_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7dd900-f1ec-4329-84bd-8ece5dc41419",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)\n",
    "\n",
    "    def init_weights(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            torch.nn.init.uniform(m.weight,  -3*1.e-4, 3*1.e-4)\n",
    "            m.bias.data.fill_(0.0001)\n",
    "\n",
    "class ActorNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ActorNet, self).__init__()\n",
    "        self.shared_layers = nn.Sequential( # todo: name\n",
    "            nn.Conv2d(4, 32, kernel_size=8, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(start_dim=0),\n",
    "            nn.Linear(64*12*12, 5),\n",
    "        )\n",
    "        self.shared_layers.apply(init_weights)\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = torch.tensor(x, dtype=torch.float)\n",
    "        hidden = self.shared_layers(input_tensor)\n",
    "        #output = self.output(hidden)\n",
    "        actions_probs = Categorical(F.softmax(hidden, dim=-1))\n",
    "\n",
    "        return actions_probs, hidden\n",
    "\n",
    "class CriticNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CriticNet, self).__init__()\n",
    "        self.shared_layers = nn.Sequential(  # todo: name\n",
    "            nn.Conv2d(4, 32, kernel_size=8, stride=4, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(start_dim=0),\n",
    "            nn.Linear(64 * 12 * 12, 1),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        input_tensor = torch.FloatTensor(x)\n",
    "        hidden = self.shared_layers(input_tensor)\n",
    "\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5914c78-bcd4-498e-be74-5bb539a436ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m94",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m94"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
